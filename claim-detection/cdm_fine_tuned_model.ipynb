{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a639af",
   "metadata": {},
   "source": [
    "### Vision Fine-tuning on GPT-4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15dd53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i1032745\\AppData\\Local\\Temp\\ipykernel_1932\\3442752263.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"label\", group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 images\n",
      "Sample data:\n",
      "                                                path    label\n",
      "0  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  claimed\n",
      "1  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  claimed\n",
      "2  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  claimed\n",
      "3  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  claimed\n",
      "4  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  claimed\n",
      "\n",
      "Label distribution:\n",
      "unclaimed: 190 images (72.5%)\n",
      "claimed: 72 images (27.5%)\n",
      "\n",
      "Limited to 30 images\n",
      "\n",
      "Limited dataset label distribution:\n",
      "unclaimed: 21 images (72.4%)\n",
      "claimed: 8 images (27.6%)\n",
      "\n",
      "Data split statistics:\n",
      "train: 20 images (69.0%)\n",
      "val: 6 images (20.7%)\n",
      "test: 3 images (10.3%)\n",
      "\n",
      "Train set label distribution:\n",
      "unclaimed: 14 images (70.0%)\n",
      "claimed: 6 images (30.0%)\n",
      "\n",
      "Validation set label distribution:\n",
      "unclaimed: 5 images (83.3%)\n",
      "claimed: 1 images (16.7%)\n",
      "\n",
      "Test set label distribution:\n",
      "unclaimed: 2 images (66.7%)\n",
      "claimed: 1 images (33.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding images to base64: 100%|██████████| 20/20 [00:00<00:00, 77.46it/s]\n",
      "Encoding images to base64: 100%|██████████| 6/6 [00:00<00:00, 82.83it/s]\n",
      "Encoding images to base64: 100%|██████████| 3/3 [00:00<00:00, 78.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample train row with new columns:\n",
      "filename                                           IMG_8873.JPG\n",
      "base64_uri    data:image/jpeg;base64,/9j/4S7jRXhpZgAATU0AKgA...\n",
      "Name: 173, dtype: object\n",
      "\n",
      "Sample val row with new columns:\n",
      "filename                                           IMG_9272.JPG\n",
      "base64_uri    data:image/jpeg;base64,/9j/4SjFRXhpZgAATU0AKgA...\n",
      "Name: 128, dtype: object\n",
      "\n",
      "Sample test row with new columns:\n",
      "filename                                           IMG_9281.JPG\n",
      "base64_uri    data:image/jpeg;base64,/9j/4S6XRXhpZgAATU0AKgA...\n",
      "Name: 137, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import base64, cv2, json, random, os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_df(img_dir: Path):\n",
    "    records = []\n",
    "    \n",
    "    # We now know the folder structure is more complex with nested folders\n",
    "    for label_dir_name in [\"claimed\", \"unclaimed\"]:\n",
    "        label_dir = img_dir / label_dir_name\n",
    "        if not label_dir.exists():\n",
    "            print(f\"Directory {label_dir} doesn't exist\")\n",
    "            continue\n",
    "            \n",
    "        # Recursively find all image files under this label directory\n",
    "        for root, dirs, files in os.walk(label_dir):\n",
    "            root_path = Path(root)\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    file_path = root_path / file\n",
    "                    records.append({\"path\": str(file_path), \"label\": label_dir_name})\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Using Path to handle relative paths correctly - going up one directory then to claim-img\n",
    "script_dir = Path.cwd()  # Use current working directory in notebooks\n",
    "img_dir = Path(r\"d:\\github-repo-tkhongsap\\vision-fine-tuning\\claim-img\")\n",
    "df = build_df(img_dir)\n",
    "\n",
    "# Debug print to see if we're getting data\n",
    "print(f\"Found {len(df)} images\")\n",
    "if len(df) > 0:\n",
    "    print(\"Sample data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Print label distribution\n",
    "    label_counts = df[\"label\"].value_counts()\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    for label, count in label_counts.items():\n",
    "        percentage = count/len(df)*100\n",
    "        print(f\"{label}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "    # Limit to only 30 images, but maintain class balance\n",
    "    if len(df) > 30:\n",
    "        # Stratified sampling to maintain label distribution\n",
    "        df = df.groupby(\"label\", group_keys=False).apply(\n",
    "            lambda x: x.sample(min(len(x), int(30 * len(x) / len(df))), random_state=42)\n",
    "        )\n",
    "        # If we don't have exactly 30 due to rounding, adjust\n",
    "        if len(df) > 30:\n",
    "            df = df.sample(30, random_state=42)\n",
    "        elif len(df) < 30:\n",
    "            # This is unlikely but just in case\n",
    "            remaining = 30 - len(df)\n",
    "            excluded = pd.concat([df, df]).drop_duplicates(keep=False)\n",
    "            if len(excluded) >= remaining:\n",
    "                df = pd.concat([df, excluded.sample(remaining, random_state=42)])\n",
    "        \n",
    "        print(f\"\\nLimited to 30 images\")\n",
    "        \n",
    "        # Print updated label distribution\n",
    "        limited_label_counts = df[\"label\"].value_counts()\n",
    "        print(\"\\nLimited dataset label distribution:\")\n",
    "        for label, count in limited_label_counts.items():\n",
    "            percentage = count/len(df)*100\n",
    "            print(f\"{label}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "    # 70 / 20 / 10 split – but ALWAYS stratified by label\n",
    "    train_df, tmp_df = train_test_split(df, test_size=0.30, stratify=df[\"label\"], random_state=42)\n",
    "    val_df, test_df  = train_test_split(tmp_df, test_size=1/3, stratify=tmp_df[\"label\"], random_state=42)\n",
    "\n",
    "    print(f\"\\nData split statistics:\")\n",
    "    print(f\"train: {len(train_df)} images ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"val: {len(val_df)} images ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"test: {len(test_df)} images ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Print label distribution in each split\n",
    "    print(\"\\nTrain set label distribution:\")\n",
    "    train_label_counts = train_df[\"label\"].value_counts()\n",
    "    for label, count in train_label_counts.items():\n",
    "        percentage = count/len(train_df)*100\n",
    "        print(f\"{label}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nValidation set label distribution:\")\n",
    "    val_label_counts = val_df[\"label\"].value_counts()\n",
    "    for label, count in val_label_counts.items():\n",
    "        percentage = count/len(val_df)*100\n",
    "        print(f\"{label}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nTest set label distribution:\")\n",
    "    test_label_counts = test_df[\"label\"].value_counts()\n",
    "    for label, count in test_label_counts.items():\n",
    "        percentage = count/len(test_df)*100\n",
    "        print(f\"{label}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "    # --- Add filename and base64_uri columns ---\n",
    "    def get_mime_type(filename):\n",
    "        ext = filename.lower().split('.')[-1]\n",
    "        if ext in [\"jpg\", \"jpeg\"]:\n",
    "            return \"image/jpeg\"\n",
    "        elif ext == \"png\":\n",
    "            return \"image/png\"\n",
    "        else:\n",
    "            return \"application/octet-stream\"\n",
    "\n",
    "    def add_filename_and_base64(df):\n",
    "        df = df.copy()\n",
    "        df[\"filename\"] = df[\"path\"].apply(lambda p: Path(p).name)\n",
    "        base64_uris = []\n",
    "        for path in tqdm(df[\"path\"], desc=\"Encoding images to base64\"):\n",
    "            try:\n",
    "                with open(path, \"rb\") as f:\n",
    "                    img_bytes = f.read()\n",
    "                mime = get_mime_type(path)\n",
    "                b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "                uri = f\"data:{mime};base64,{b64}\"\n",
    "                base64_uris.append(uri)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encoding {path}: {e}\")\n",
    "                base64_uris.append(\"\")\n",
    "        df[\"base64_uri\"] = base64_uris\n",
    "        return df\n",
    "\n",
    "    train_df = add_filename_and_base64(train_df)\n",
    "    val_df = add_filename_and_base64(val_df)\n",
    "    test_df = add_filename_and_base64(test_df)\n",
    "\n",
    "    print(\"\\nSample train row with new columns:\")\n",
    "    print(train_df.iloc[0][[\"filename\", \"base64_uri\"]])\n",
    "    print(\"\\nSample val row with new columns:\")\n",
    "    print(val_df.iloc[0][[\"filename\", \"base64_uri\"]])\n",
    "    print(\"\\nSample test row with new columns:\")\n",
    "    print(test_df.iloc[0][[\"filename\", \"base64_uri\"]])\n",
    "else:\n",
    "    print(\"No images found. Check the directory path and structure.\")\n",
    "    print(f\"Looking for images in: {img_dir}\")\n",
    "    print(f\"Does directory exist: {img_dir.exists()}\")\n",
    "    if img_dir.exists():\n",
    "        print(\"Directory contents:\")\n",
    "        for item in img_dir.iterdir():\n",
    "            print(f\"  - {item.name} ({'dir' if item.is_dir() else 'file'})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d55cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20 entries, 173 to 167\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   path        20 non-null     object\n",
      " 1   label       20 non-null     object\n",
      " 2   filename    20 non-null     object\n",
      " 3   base64_uri  20 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 800.0+ bytes\n",
      "None\n",
      "\n",
      "Validation DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6 entries, 128 to 181\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   path        6 non-null      object\n",
      " 1   label       6 non-null      object\n",
      " 2   filename    6 non-null      object\n",
      " 3   base64_uri  6 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 240.0+ bytes\n",
      "None\n",
      "\n",
      "Test DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, 137 to 10\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   path        3 non-null      object\n",
      " 1   label       3 non-null      object\n",
      " 2   filename    3 non-null      object\n",
      " 3   base64_uri  3 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 120.0+ bytes\n",
      "None\n",
      "\n",
      "Sample rows from Train DataFrame:\n",
      "                                                  path      label  \\\n",
      "173  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "50   d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...    claimed   \n",
      "28   d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...    claimed   \n",
      "62   d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...    claimed   \n",
      "247  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "\n",
      "         filename                                         base64_uri  \n",
      "173  IMG_8873.JPG  data:image/jpeg;base64,/9j/4S7jRXhpZgAATU0AKgA...  \n",
      "50   IMG_8928.JPG  data:image/jpeg;base64,/9j/4S5wRXhpZgAATU0AKgA...  \n",
      "28   IMG_8904.JPG  data:image/jpeg;base64,/9j/4SuvRXhpZgAATU0AKgA...  \n",
      "62   IMG_8942.JPG  data:image/jpeg;base64,/9j/4S04RXhpZgAATU0AKgA...  \n",
      "247  IMG_9015.JPG  data:image/jpeg;base64,/9j/4SniRXhpZgAATU0AKgA...  \n",
      "\n",
      "Sample rows from Validation DataFrame:\n",
      "                                                  path      label  \\\n",
      "128  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "0    d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...    claimed   \n",
      "192  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "88   d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "81   d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "\n",
      "         filename                                         base64_uri  \n",
      "128  IMG_9272.JPG  data:image/jpeg;base64,/9j/4SjFRXhpZgAATU0AKgA...  \n",
      "0    IMG_8860.JPG  data:image/jpeg;base64,/9j/4SV9RXhpZgAATU0AKgA...  \n",
      "192  IMG_8958.JPG  data:image/jpeg;base64,/9j/4Su/RXhpZgAATU0AKgA...  \n",
      "88   IMG_9551.JPG  data:image/jpeg;base64,/9j/4SlSRXhpZgAATU0AKgA...  \n",
      "81   IMG_9527.JPG  data:image/jpeg;base64,/9j/4SvtRXhpZgAATU0AKgA...  \n",
      "\n",
      "Sample rows from Test DataFrame:\n",
      "                                                  path      label  \\\n",
      "137  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "114  d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...  unclaimed   \n",
      "10   d:\\github-repo-tkhongsap\\vision-fine-tuning\\cl...    claimed   \n",
      "\n",
      "         filename                                         base64_uri  \n",
      "137  IMG_9281.JPG  data:image/jpeg;base64,/9j/4S6XRXhpZgAATU0AKgA...  \n",
      "114  IMG_9258.JPG  data:image/jpeg;base64,/9j/4TFIRXhpZgAATU0AKgA...  \n",
      "10   IMG_8870.JPG  data:image/jpeg;base64,/9j/4S0MRXhpZgAATU0AKgA...  \n"
     ]
    }
   ],
   "source": [
    "# Display the columns and their data types for each split\n",
    "print(\"\\nTrain DataFrame Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nValidation DataFrame Info:\")\n",
    "print(val_df.info())\n",
    "\n",
    "print(\"\\nTest DataFrame Info:\")\n",
    "print(test_df.info())\n",
    "\n",
    "# Show sample rows from each split to verify data\n",
    "print(\"\\nSample rows from Train DataFrame:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nSample rows from Validation DataFrame:\")\n",
    "print(val_df.head())\n",
    "\n",
    "print(\"\\nSample rows from Test DataFrame:\")\n",
    "print(test_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40dffe5",
   "metadata": {},
   "source": [
    "## Constructing the Training, Validation, and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c2672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote   20 lines  →  data_jsonl\\train.jsonl\n",
      "Wrote    6 lines  →  data_jsonl\\val.jsonl\n",
      "Wrote    3 lines  →  data_jsonl\\test.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an assistant that decides whether a bottle can be returned for a deposit refund.\n",
    "Look at the image and answer with exactly one word: “claimable” or “non-claimable”.\n",
    "\"\"\"\n",
    "\n",
    "def row_to_chat_json(row: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Map one DataFrame row to the 3-turn chat format:\n",
    "      system  - your fixed instructions\n",
    "      user    - ALWAYS the same question + the image\n",
    "      assistant - ground-truth (claimable / non-claimable)\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYSTEM_PROMPT.strip()\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Is the bottle claimable?\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": row[\"base64_uri\"]}}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": row[\"label\"]}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def df_to_jsonl(df: pd.DataFrame, out_path: Path):\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            json_line = row_to_chat_json(row)\n",
    "            f.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"Wrote {len(df):>4} lines  →  {out_path}\")\n",
    "\n",
    "data_dir = Path(\"data_jsonl\"); data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "df_to_jsonl(train_df, data_dir / \"train.jsonl\")\n",
    "df_to_jsonl(val_df,   data_dir / \"val.jsonl\")\n",
    "df_to_jsonl(test_df,  data_dir / \"test.jsonl\")   # keep only locally\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81046494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, ChatCompletion\n",
    "import json\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "# upload training file\n",
    "train_file = client.files.create(\n",
    "  file=open(\"data_jsonl/train.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# upload validation file\n",
    "val_file = client.files.create(\n",
    "  file=open(\"data_jsonl/val.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf0390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
